{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归原理及实践\n",
    "线性回归通过一个线性模型来适配观测数据，这个线性模型是在特征和响应之间构建一个关系。目的是预测当前被观察的对象的值。线性回归的实现过程主要包括建立线性模型和选择优化方法求解参数两部分。\n",
    "### 1. 建立线性模型\n",
    "想要一个成功的回归分析，在建立线性模型之前，确认以下信息很重要：  \n",
    "**线性：**特征值与和预测值是线性相关  \n",
    "**不含多重共线性：**数据有极少或没有多重共线性，当特征不是相互独立时，会引发多重共线性。  \n",
    "**多元正态分布：**多元回归残差符合正态分布。  \n",
    "**虚拟变量：** 当遇到数据是非数值数据类型时，使用分类数据是一个非常有效的方法。分据数据，是指反映事物类别的数据，是离散数据，其数值个数有限且值之间无序。比如，按性别分为男，女两类。在一个回归模中，这些分类值可以用虚拟变量来表示，变量通常取如1或0这样的值，来表示肯定或否定类型。  \n",
    "**虚拟变量陷进：**虚拟变量陷进是指两个及以上变量之间高度相关的情形。简而言之，就是存在一个能够被其他变量预测出的变量，举一个存在重复类别的直观例子：对于男性类别，该类别也可以通过女性类别来定义，女性值为0时，表示男性，值为1时表示女性，反之亦然。解决虚拟变量陷进的方法是，类别变量数减去1，假如有m个类别，那么在模型构建时取(m-1)个虚拟变量，减去的那个变量可以看作是参考值。   \n",
    "给定训练集: $X_{train} = (x^{(1)},x^{(2)},x^{(3)},...,x^{(i)})$，对于单个输入$x^{(i)}=(x_{1}^{(i)},x_{2}^{(i)},...,x_{n}^{(i)})$, 可得到线性模型为：\n",
    "$$\\hat{y}^{(i)} = w^T x^{(i)} + b = w_{1}x_{1}^{(i)}+w_{2}x_{2}^{(i)}+...+w_{n-1}x_{n-1}^{(i)}+w_{n}x_{n}^{(i)}+b\\tag{1}$$\n",
    "对应的损失函数$ \\mathcal{L}(\\hat{y}^{(i)}, y^{(i)}) $为：\n",
    "$$ \\mathcal{L}(\\hat{y}^{(i)}, y^{(i)}) = \\frac{1}{2} (\\hat{y}^{(i)}-y^{(i)})^{2}\\tag{2} $$\n",
    "然后通过对所有训练样例求和来计算代价函数：\n",
    "$$ J = \\frac{1}{2m} \\sum_{i=1}^m \\mathcal{L}(\\hat{y}^{(i)}, y^{(i)})\\tag{3}$$\n",
    "### 2. 选择优化方法\n",
    "计算出代价函数后，需要选择优化方法来最小化代价函数，以得到合适的参数w和b。线性回归常用的优化方法为梯度下降法和最小二乘法。\n",
    "#### 2.1 梯度下降法 \n",
    "梯度下降法的过程为：首先执行前向传播和反向传播，然后根据反向传播得到的各个参数的偏导数，进行参数的更新。  \n",
    "**前向传播**  \n",
    "对于输入$X$，线性回归的预测值为：\n",
    "$$\\hat{Y} = w^T X + b = (\\hat{y}^{(1)}, \\hat{y}^{(2)}, ..., \\hat{y}^{(m-1)}, \\hat{y}^{(m)})\\tag{4}$$\n",
    "通过已知的训练数据与得到的预测值，可得到代价函数：\n",
    "$$ J = \\frac{1}{2m} \\sum_{i=1}^m (\\hat{y}^{(i)}-y^{(i)})^{2}\\tag{5}$$\n",
    "**反向传播**\n",
    "$$ dW = \\frac{\\partial J}{\\partial W} = \\frac{1}{m}X(\\hat{Y}-Y)^T\\tag{6}$$\n",
    "$$ db = \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}^{(i)}-y^{(i)})\\tag{7}$$\n",
    "**更新参数**\n",
    "$$ w = w - \\alpha*dW\\tag{8}$$\n",
    "$$ b = b - \\alpha*db\\tag{9}$$\n",
    "其中，$\\alpha$为学习速率。\n",
    "#### 2.2 最小二乘法\n",
    "最小二乘法是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。\n",
    "对于输入$X$，$\\hat{Y} = w^T X + b$可转换为：\n",
    "$$ W = \\begin{bmatrix}w \\\\b \\end{bmatrix}, \\ X = \\begin{bmatrix}X \\\\1 \\end{bmatrix} \\tag{10}$$\n",
    "得到转换后的模型为：\n",
    "$$\\hat{Y} = W^T X \\tag{11}$$\n",
    "对应的损失函数：\n",
    "$$ J = \\frac{1}{2m} \\sum_{i=1}^m (\\hat{y}^{(i)}-y^{(i)})^{2} = \\frac{1}{2m} (\\hat{Y}-Y)^{T}(\\hat{Y}-Y) \\tag{12}$$\n",
    "求出$dW$，并令$dW=0$，得到：\n",
    "$$ dW = \\frac{\\partial J}{\\partial W} = \\frac{1}{m}X(\\hat{Y}-Y)^T = \\frac{1}{m}(XX^{T}W - XY) = 0 \\tag{13}$$\n",
    "求解得：\n",
    "$$ W = (XX^{T})^{-1}XY \\tag{14}$$\n",
    "由公式(14)可知，线性回归可用最小二乘法求解参数的条件是$(XX^{T})$可逆，即矩阵$X$满秩。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习目标\n",
    "- 构建学习算法的通用框架，主要包括：\n",
    "  - 数据预处理\n",
    "  - 初始化参数\n",
    "  - 计算代价函数及其梯度\n",
    "  - 使用优化算法（最小二乘法，梯度下降法）\n",
    "- 构建简单线性回归模型分析数据\n",
    "- 构建多元线性回归模型分析数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建简单线性回归模型分析数据\n",
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ruanjian\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据集\n",
    "**数据集介绍：**  \n",
    "该数据集共25个数据项，特征为Hours(时长)，要预测的值为Scores(分数)。  \n",
    "**查看数据集前5行**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hours  Scores\n",
       "0    2.5      21\n",
       "1    5.1      47\n",
       "2    3.2      27\n",
       "3    8.5      75\n",
       "4    3.5      30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('datasets/studentscores.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    data = np.loadtxt(\"datasets/studentscores.csv\", dtype=np.str, delimiter=\",\")\n",
    "    X_train = data[1:,:1].astype(np.float)\n",
    "    y_train = data[1:,-1].astype(np.float)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train= load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拆分数据集为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X_train, y_train, test_size = 1/4, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集矢量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_train.T.reshape(1,-1), y_train.T.reshape(1,-1)\n",
    "X_test, y_test = X_test.T.reshape(1,-1), y_test.T.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 梯度下降法\n",
    "### 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    此函数为w创建一个形状为（dim，1）的零向量，并将b初始化为0。\n",
    "    \n",
    "    输入：\n",
    "    dim -- w向量的大小 \n",
    "    \n",
    "    输出:\n",
    "    w -- 初始化的向量\n",
    "    b -- 初始化的偏差\n",
    "    \"\"\"\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算代价函数及其梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    实现前向传播的代价函数及反向传播的梯度\n",
    "\n",
    "    输入:\n",
    "    w -- 权重, 一个numpy数组，大小为(特征数, 1)\n",
    "    b -- 偏差, 一个标量\n",
    "    X -- 训练数据，大小为 (特征数 , 样本数量)\n",
    "    Y -- 真实\"标签\"向量，大小为(1, 样本数量)\n",
    "\n",
    "    输出:\n",
    "    cost -- 线性回归的代价函数\n",
    "    dw -- 相对于w的损失梯度，因此与w的形状相同\n",
    "    db -- 相对于b的损失梯度，因此与b的形状相同\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # 前向传播\n",
    "    Y_hat = np.dot(w.T,X)+b\n",
    "    cost = np.dot((Y_hat - Y),(Y_hat - Y).T)/(2*m)\n",
    "    \n",
    "    # 反向传播\n",
    "    dw = np.dot(X,(Y_hat-Y).T)/m\n",
    "    db = np.sum(Y_hat-Y)/m\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降法优化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    此函数通过运行梯度下降算法来优化w和b\n",
    "    \n",
    "    输入:\n",
    "    w -- 权重, 一个numpy数组，大小为(特征数, 1)\n",
    "    b -- 偏差, 一个标量\n",
    "    X -- 训练数据，大小为 (特征数 , 样本数量)\n",
    "    Y -- 真实\"标签\"向量，大小为(1, 样本数量)\n",
    "    num_iterations -- 优化循环的迭代次数\n",
    "    learning_rate -- 梯度下降更新规则的学习率\n",
    "    print_cost -- 是否每200步打印一次成本\n",
    "    \n",
    "    输出:\n",
    "    params -- 存储权重w和偏见b的字典\n",
    "    grads -- 存储权重梯度相对于代价函数偏导数的字典\n",
    "    costs -- 在优化期间计算的所有损失的列表，这将用于绘制学习曲线。\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # 成本和梯度计算\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # 更新参数\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        # 记录成本\n",
    "        if i % 200 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # 每200次训练迭代打印成本\n",
    "        if i % 200 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 最小二乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(X, Y):\n",
    "    '''\n",
    "    最小二乘法求解参数w,b\n",
    "    \n",
    "    输入:\n",
    "    X -- 训练数据，大小为 (特征数 , 样本数量)\n",
    "    Y -- 真实值向量，大小为(1, 样本数量)\n",
    "    输出：\n",
    "    w -- 权重, 一个numpy数组，大小为(特征数, 1)\n",
    "    b -- 偏差, 一个标量\n",
    "    '''\n",
    "    X = np.concatenate((X,np.ones((1,X.shape[1]))),axis=0)\n",
    "    W = np.dot(np.linalg.inv(np.dot(X,X.T)),np.dot(X,Y.T))\n",
    "    w = W[:-1]\n",
    "    b = W[-1]\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    '''\n",
    "    使用线性回归参数（w，b）预测结果\n",
    "    \n",
    "    输入:\n",
    "    w -- 权重, 一个numpy数组，大小为(特征数, 1)\n",
    "    b -- 偏差, 一个标量\n",
    "    X -- 训练数据，大小为 (特征数 , 样本数量)\n",
    "    \n",
    "    输出:\n",
    "    Y_prediction -- 包含X中示例的所有预测（0/1）的numpy数组（向量）\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    Y_prediction = np.dot(w.T,X)+b\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, optimization = \"gradient descent\",num_iterations = 2000, learning_rate = 0.5):\n",
    "    \"\"\"\n",
    "    通过调用前面实现的函数来构建线性回归模型\n",
    "    \n",
    "    输入:\n",
    "    X_train -- 由numpy数组表示的训练集，大小为 (特征数，训练样本数)\n",
    "    Y_train -- 由numpy数组（向量）表示的训练标签，大小为 (1, 训练样本数)\n",
    "    X_test -- 由numpy数组表示的测试集，大小为（特征数，测试样本数）\n",
    "    Y_test -- 由numpy数组（向量）表示的测试标签，大小为 (1, 测试样本数)\n",
    "    optimization -- 选择优化方法，设为\"gradient descent\"时为梯度下降法，设为\"least squares\"时为最小二乘法。\n",
    "    num_iterations -- 超参数，表示优化参数的迭代次数\n",
    "    learning_rate -- 超参数，在优化算法更新规则中使用的学习率\n",
    "    \n",
    "    输出:\n",
    "    d -- 包含模型信息的字典。\n",
    "    \"\"\"\n",
    "    if optimization == \"gradient descent\":\n",
    "        # 初始化参数\n",
    "        w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "        # 梯度下降\n",
    "        parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate)\n",
    "    \n",
    "        # 从字典“parameters”中检索参数w和b\n",
    "        w = parameters[\"w\"]\n",
    "        b = parameters[\"b\"]   \n",
    "    elif optimization == \"least squares\":\n",
    "        w, b = least_squares(X_train, Y_train)\n",
    "    else:\n",
    "        print(\"TypeError: model() got an unexpected keyword argument 'optimize'\")\n",
    "    # 预测测试/训练集\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    # 打印测试集的预测结果\n",
    "    print(\"Test data predict value : {}\".format(Y_prediction_test))\n",
    "    print(\"The test data true value: {}\".format(Y_test))\n",
    "    \n",
    "    d = {\"Y_prediction_test\": Y_prediction_test,\n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data predict value : [[16.84472176 33.74557494 75.50062397 26.7864001  60.58810646 39.71058194\n",
      "  20.8213931 ]]\n",
      "The test data true value: [[20. 27. 69. 30. 62. 35. 24.]]\n"
     ]
    }
   ],
   "source": [
    "d_simple = model(X_train, y_train, X_test, y_test, optimization = \"least squares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1db0dafe748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.squeeze(X_train), np.squeeze(y_train), color = 'red')\n",
    "plt.plot(np.squeeze(X_train), np.squeeze(d_simple[\"Y_prediction_train\"]), color ='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1db0e22e588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.squeeze(X_test), np.squeeze(y_test), color = 'red')\n",
    "plt.plot(np.squeeze(X_test), np.squeeze(d_simple[\"Y_prediction_test\"]), color ='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建多元线性回归模型分析数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据集\n",
    "**数据集介绍：**  \n",
    "该数据集共50个数据项，特征分别为：R&D Spend(研发花费)，Administration(管理经费)，Marketing Spend(市场花费)，state(州)。要预测的内容为Profit(盈利)。\n",
    "**查看数据集前5行**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('datasets/50_Startups.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    data = np.loadtxt(\"datasets/50_Startups.csv\", dtype=np.str, delimiter=\",\")\n",
    "    X_train = data[1:,:3].astype(np.float)\n",
    "    X_dummy = data[1:,3]\n",
    "    y_train = data[1:,-1].astype(np.float)\n",
    "    return X_train, X_dummy, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, X_dummy, train_y = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用分类数据方法处理虚拟变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_variable(X):\n",
    "    '''\n",
    "    输入：\n",
    "    X -- 虚拟变量\n",
    "    输出：\n",
    "    set_dummy -- 使用分类数据方法处理虚拟变量后的数组\n",
    "    '''\n",
    "    num_dummy = len(set(X))\n",
    "    set_dummy = np.zeros((X.shape[0],num_dummy))\n",
    "    for i in range(num_dummy):\n",
    "        set_dummy[:,i][np.where(X==list(set(X))[i])] = 1.\n",
    "    return set_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dummy = dummy_variable(X_dummy)  \n",
    "train_set_x = np.concatenate((train_X,set_dummy),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 躲避虚拟变量陷阱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X):\n",
    "    '''\n",
    "    输入：\n",
    "    X -- 训练数据，大小为(特征数, 样本数量)\n",
    "    输出：\n",
    "    X -- 归一化后的训练数据，大小为(特征数, 样本数量)\n",
    "    x_max -- 原训练数据中每类特征的最大值\n",
    "    x_min -- 原训练数据中每类特征的最小值\n",
    "    ''' \n",
    "    x_max = np.max(X,axis=0,keepdims=True)\n",
    "    x_min = np.min(X,axis=0,keepdims=True)\n",
    "    X = (X - x_min)/(x_max - x_min)\n",
    "    return X,x_max,x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x,x_max,x_min = normalization(train_set_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拆分数据集为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x, test_set_x, train_set_y, test_set_y = train_test_split(train_set_x, train_y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数据集转换为矢量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x, train_set_y = train_set_x.T, train_set_y.T.reshape(1,-1)\n",
    "test_set_x, test_set_y = test_set_x.T, test_set_y.T.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练与测试\n",
    "#### 使用最小二乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data predict value : [[103015.20159796 132582.27760816 132447.73845174  71976.09851258\n",
      "  178537.48221055 116161.24230165  67851.69209676  98791.73374687\n",
      "  113969.43533012 167921.0656955 ]]\n",
      "The test data true value: [[103282.38 144259.4  146121.95  77798.83 191050.39 105008.31  81229.06\n",
      "   97483.56 110352.25 166187.94]]\n"
     ]
    }
   ],
   "source": [
    "d_multiple1 = model(train_set_x, train_set_y, test_set_x, test_set_y, optimization = \"least squares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 6807997862.101883\n",
      "Cost after iteration 200: 43371803.699051\n",
      "Cost after iteration 400: 40947393.054603\n",
      "Cost after iteration 600: 40795651.773923\n",
      "Cost after iteration 800: 40786137.392499\n",
      "Cost after iteration 1000: 40785540.810488\n",
      "Cost after iteration 1200: 40785503.402879\n",
      "Cost after iteration 1400: 40785501.057301\n",
      "Cost after iteration 1600: 40785500.910226\n",
      "Cost after iteration 1800: 40785500.901004\n",
      "Cost after iteration 2000: 40785500.900426\n",
      "Cost after iteration 2200: 40785500.900389\n",
      "Cost after iteration 2400: 40785500.900387\n",
      "Cost after iteration 2600: 40785500.900387\n",
      "Cost after iteration 2800: 40785500.900387\n",
      "Test data predict value : [[103015.20160276 132582.27759601 132447.7384391   71976.09850775\n",
      "  178537.48219813 116161.24231955  67851.69209773  98791.73374919\n",
      "  113969.43533513 167921.06567985]]\n",
      "The test data true value: [[103282.38 144259.4  146121.95  77798.83 191050.39 105008.31  81229.06\n",
      "   97483.56 110352.25 166187.94]]\n"
     ]
    }
   ],
   "source": [
    "d_multiple2 = model(train_set_x, train_set_y, test_set_x, test_set_y, optimization = \"gradient descent\", num_iterations = 3000, learning_rate = 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
